{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c08577d4-e409-4563-b0a9-0544caf4c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet-pytorch in c:\\users\\ed007\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from facenet-pytorch) (1.26.4)\n",
      "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from facenet-pytorch) (10.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from facenet-pytorch) (2.32.3)\n",
      "Requirement already satisfied: torch<2.3.0,>=2.2.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from facenet-pytorch) (2.2.2)\n",
      "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from facenet-pytorch) (0.17.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from facenet-pytorch) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.6.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2024.6.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.0.0->facenet-pytorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install facenet-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5897bc54-5cd1-44a6-8f41-79e67cd2cbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493.jpg\n",
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493_01.jpg\n",
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493_02.jpg\n",
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493_03.jpg\n",
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493_04.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493.jpg → sample\\KakaoTalk_20250708_173306493.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493_01.jpg → sample\\KakaoTalk_20250708_173306493_01.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493_02.jpg → sample\\KakaoTalk_20250708_173306493_02.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493_03.jpg → sample\\KakaoTalk_20250708_173306493_03.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493_04.jpg → sample\\KakaoTalk_20250708_173306493_04.jpg\n",
      "[Info] 'sample' 폴더에 5개 파일을 업로드했습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def reload_sample_folder(sample_dir='sample'):\n",
    "    \"\"\"\n",
    "    sample_dir 폴더 내 삭제 가능한 파일들만 지운 뒤,\n",
    "    파일 선택 대화상자로 고른 이미지들을 모두 복사해 넣습니다.\n",
    "    \"\"\"\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    # 기존 파일 삭제 시도\n",
    "    for fname in os.listdir(sample_dir):\n",
    "        fp = os.path.join(sample_dir, fname)\n",
    "        try:\n",
    "            os.remove(fp)\n",
    "            print(f\"[Info] 삭제: {fp}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] 삭제 실패(잠금?): {fp} ({e})\")\n",
    "\n",
    "    # 파일 선택\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    paths = filedialog.askopenfilenames(\n",
    "        title=\"타깃 인물 샘플 이미지를 다시 선택하세요\",\n",
    "        filetypes=[(\"Image files\",\"*.jpg *.jpeg *.png\"), (\"All files\",\"*.*\")]\n",
    "    )\n",
    "    if not paths:\n",
    "        print(\"[Warning] 이미지가 선택되지 않았습니다.\")\n",
    "        return\n",
    "\n",
    "    # 선택된 파일 복사\n",
    "    for src in paths:\n",
    "        dst = os.path.join(sample_dir, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"[Info] 복사: {src} → {dst}\")\n",
    "\n",
    "    print(f\"[Info] '{sample_dir}' 폴더에 {len(paths)}개 파일을 업로드했습니다.\")\n",
    "\n",
    "# 사용 예시: 스크립트 시작 부분에 호출\n",
    "if __name__ == '__main__':\n",
    "    reload_sample_folder()  # sample/ 폴더 재업로드\n",
    "    # …이어서 나머지 파이프라인 코드…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e821fef2-a98a-4682-b0d2-ec448ea579af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493.jpg\n",
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493_01.jpg\n",
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493_02.jpg\n",
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493_03.jpg\n",
      "[Info] 삭제: sample\\KakaoTalk_20250708_173306493_04.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493.jpg → sample\\KakaoTalk_20250708_173306493.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493_01.jpg → sample\\KakaoTalk_20250708_173306493_01.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493_02.jpg → sample\\KakaoTalk_20250708_173306493_02.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493_03.jpg → sample\\KakaoTalk_20250708_173306493_03.jpg\n",
      "[Info] 복사: C:/Users/ed007/OneDrive/Documents/카카오톡 받은 파일/KakaoTalk_20250708_173306493_04.jpg → sample\\KakaoTalk_20250708_173306493_04.jpg\n",
      "[Info] 'sample' 폴더에 5개 파일을 업로드했습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def reload_sample_folder(sample_dir='sample'):\n",
    "    \"\"\"\n",
    "    sample_dir 폴더 내 삭제 가능한 파일들만 지운 뒤,\n",
    "    파일 선택 대화상자로 고른 이미지들을 모두 복사해 넣습니다.\n",
    "    \"\"\"\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "    # 기존 파일 삭제 시도\n",
    "    for fname in os.listdir(sample_dir):\n",
    "        fp = os.path.join(sample_dir, fname)\n",
    "        try:\n",
    "            os.remove(fp)\n",
    "            print(f\"[Info] 삭제: {fp}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[Warning] 삭제 실패(잠금?): {fp} ({e})\")\n",
    "\n",
    "    # 파일 선택\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    paths = filedialog.askopenfilenames(\n",
    "        title=\"타깃 인물 샘플 이미지를 다시 선택하세요\",\n",
    "        filetypes=[(\"Image files\",\"*.jpg *.jpeg *.png\"), (\"All files\",\"*.*\")]\n",
    "    )\n",
    "    if not paths:\n",
    "        print(\"[Warning] 이미지가 선택되지 않았습니다.\")\n",
    "        return\n",
    "\n",
    "    # 선택된 파일 복사\n",
    "    for src in paths:\n",
    "        dst = os.path.join(sample_dir, os.path.basename(src))\n",
    "        shutil.copy(src, dst)\n",
    "        print(f\"[Info] 복사: {src} → {dst}\")\n",
    "\n",
    "    print(f\"[Info] '{sample_dir}' 폴더에 {len(paths)}개 파일을 업로드했습니다.\")\n",
    "\n",
    "# 사용 예시: 스크립트 시작 부분에 호출\n",
    "if __name__ == '__main__':\n",
    "    reload_sample_folder()  # sample/ 폴더 재업로드\n",
    "    # …이어서 나머지 파이프라인 코드…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9249291d-376c-4c6a-869e-01de2b69960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] 'sample' 폴더에서 5개 파일을 찾았습니다.\n",
      "[✓ MTCNN] KakaoTalk_20250708_173306493.jpg\n",
      "[✓ MTCNN] KakaoTalk_20250708_173306493_01.jpg\n",
      "[✓ MTCNN] KakaoTalk_20250708_173306493_02.jpg\n",
      "[✗ Haar ] KakaoTalk_20250708_173306493_03.jpg – 얼굴 검출 실패\n",
      "[✓ MTCNN] KakaoTalk_20250708_173306493_04.jpg\n",
      "[Info] 총 4개의 얼굴 임베딩을 모았으며, 센트로이드 계산 완료.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image\n",
    "\n",
    "# 1) 모델 초기화\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn  = MTCNN(image_size=160, margin=20, keep_all=False, device=device)\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "haar = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    ")\n",
    "\n",
    "# 2) 샘플 폴더 경로 & 이미지 리스트\n",
    "SAMPLE_DIR = 'sample'\n",
    "paths = glob.glob(os.path.join(SAMPLE_DIR, '*'))\n",
    "print(f\"[Info] '{SAMPLE_DIR}' 폴더에서 {len(paths)}개 파일을 찾았습니다.\")\n",
    "\n",
    "# 3) 얼굴 임베딩 수집\n",
    "embs = []\n",
    "for path in paths:\n",
    "    name = os.path.basename(path)\n",
    "    # (a) MTCNN 시도\n",
    "    try:\n",
    "        img_pil = Image.open(path).convert('RGB')\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] 이미지 로드 실패: {name} ({e})\")\n",
    "        continue\n",
    "\n",
    "    face_tensor = mtcnn(img_pil)  # None or Tensor[3,160,160]\n",
    "    if face_tensor is not None:\n",
    "        print(f\"[✓ MTCNN] {name}\")\n",
    "    else:\n",
    "        # (b) MTCNN 실패 → Haar Cascade 시도\n",
    "        img_cv = cv2.imread(path)\n",
    "        gray   = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "        boxes  = haar.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "        if len(boxes) == 0:\n",
    "            print(f\"[✗ Haar ] {name} – 얼굴 검출 실패\")\n",
    "            continue\n",
    "        x, y, w, h = boxes[0]\n",
    "        crop = cv2.resize(img_cv[y:y+h, x:x+w], (160,160))\n",
    "        # BGR→RGB→Tensor\n",
    "        face_tensor = torch.from_numpy(crop[:,:,::-1])\\\n",
    "                            .permute(2,0,1).float().div(255).to(device)\n",
    "        print(f\"[✓ Haar ] {name}\")\n",
    "\n",
    "    # (c) 임베딩 추출\n",
    "    with torch.no_grad():\n",
    "        emb = resnet(face_tensor.unsqueeze(0))[0]\n",
    "    embs.append(emb.cpu().numpy())\n",
    "\n",
    "# 4) 결과 확인 및 센트로이드 계산\n",
    "if not embs:\n",
    "    raise RuntimeError(f\"[Error] '{SAMPLE_DIR}'에 유효한 얼굴 샘플이 없습니다.\")\n",
    "\n",
    "embs = np.stack(embs)\n",
    "centroid = np.mean(embs, axis=0)\n",
    "print(f\"[Info] 총 {len(embs)}개의 얼굴 임베딩을 모았으며, 센트로이드 계산 완료.\")\n",
    "\n",
    "# 이제 `centroid` 변수를 타깃 얼굴 임베딩 프로파일로 사용하시면 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf5793c4-22f9-46e5-ad67-a16ea9d53ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: facenet-pytorch in c:\\users\\ed007\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torch in c:\\users\\ed007\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ed007\\anaconda3\\lib\\site-packages (0.17.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\ed007\\anaconda3\\lib\\site-packages (10.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from facenet-pytorch) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from facenet-pytorch) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from facenet-pytorch) (4.66.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.6.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.0.0->facenet-pytorch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ed007\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# 노트북 셀에서 실행할 때\n",
    "!conda install -c conda-forge opencv -y\n",
    "!pip install facenet-pytorch torch torchvision pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2588b7cc-1ba6-411f-8106-7b438428cf6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:929: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Info] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개 샘플 이미지를 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m에 저장했습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sample_dir\n\u001b[1;32m---> 34\u001b[0m sample_dir \u001b[38;5;241m=\u001b[39m reload_sample_folder()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# ─────────────────────────────────────────────────────────────────────────────\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# 1) 모델 초기화\u001b[39;00m\n\u001b[0;32m     38\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[1;32mIn[23], line 30\u001b[0m, in \u001b[0;36mreload_sample_folder\u001b[1;34m(sample_dir)\u001b[0m\n\u001b[0;32m     28\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(sample_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m     29\u001b[0m     img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(src)\n\u001b[1;32m---> 30\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(dst, img)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Info] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개 샘플 이미지를 \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m에 저장했습니다.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sample_dir\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:929: error: (-215:Assertion failed) !_img.empty() in function 'cv::imwrite'\n"
     ]
    }
   ],
   "source": [
    "# compute_sample_centroid_simple_fixed.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 0) 대화상자로 샘플 이미지 폴더 갱신\n",
    "def reload_sample_folder(sample_dir='sample'):\n",
    "    os.makedirs(sample_dir, exist_ok=True)\n",
    "    for f in os.listdir(sample_dir):\n",
    "        try: os.remove(os.path.join(sample_dir, f))\n",
    "        except: pass\n",
    "    root = tk.Tk(); root.withdraw()\n",
    "    paths = filedialog.askopenfilenames(\n",
    "        title=\"타깃 인물 샘플 이미지들을 선택하세요\",\n",
    "        filetypes=[(\"Image files\",\"*.jpg *.jpeg *.png\"),(\"All files\",\"*.*\")]\n",
    "    )\n",
    "    if not paths:\n",
    "        raise RuntimeError(\"샘플 이미지를 하나도 선택하지 않았습니다.\")\n",
    "    for src in paths:\n",
    "        dst = os.path.join(sample_dir, os.path.basename(src))\n",
    "        img = cv2.imread(src)\n",
    "        cv2.imwrite(dst, img)\n",
    "    print(f\"[Info] {len(paths)}개 샘플 이미지를 '{sample_dir}'에 저장했습니다.\")\n",
    "    return sample_dir\n",
    "\n",
    "sample_dir = reload_sample_folder()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1) 모델 초기화\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "mtcnn = MTCNN(\n",
    "    image_size=224,\n",
    "    margin=40,\n",
    "    thresholds=[0.5, 0.6, 0.7],\n",
    "    min_face_size=20,\n",
    "    keep_all=False,\n",
    "    device=device\n",
    ")\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "haar = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2) 샘플 임베딩 수집\n",
    "paths = glob.glob(os.path.join(sample_dir, '*'))\n",
    "print(f\"[Info] '{sample_dir}'에 {len(paths)}개 파일이 있습니다.\")\n",
    "\n",
    "embs = []\n",
    "for path in paths:\n",
    "    name = os.path.basename(path)\n",
    "    print(f\"\\n[Processing] {name}\")\n",
    "\n",
    "    # (a) MTCNN 시도\n",
    "    face_t = None\n",
    "    try:\n",
    "        img_pil = Image.open(path).convert('RGB')\n",
    "        face_t = mtcnn(img_pil)  # Tensor or None\n",
    "        if face_t is not None:\n",
    "            print(\"  [✓ MTCNN]\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [Error] PIL 로드 실패: {e}\")\n",
    "\n",
    "    # (b) Haar Cascade fallback\n",
    "    if face_t is None:\n",
    "        print(\"  [.. Haar Cascade]\")\n",
    "        img_cv = cv2.imread(path)\n",
    "        gray   = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "        boxes  = haar.detectMultiScale(gray, 1.1, 5)\n",
    "        if len(boxes) > 0:\n",
    "            x,y,w,h = boxes[0]\n",
    "            crop = cv2.resize(img_cv[y:y+h, x:x+w], (224,224))\n",
    "            # reverse channels and copy to avoid negative stride\n",
    "            arr = crop[:, :, ::-1].copy()\n",
    "            face_t = torch.from_numpy(arr)\\\n",
    "                         .permute(2,0,1).float().div(255).to(device)\n",
    "            print(\"  [✓ Haar]\")\n",
    "        else:\n",
    "            print(\"  [✗ Fail] 얼굴 검출 실패\")\n",
    "            continue\n",
    "\n",
    "    # (c) 임베딩 추출\n",
    "    with torch.no_grad():\n",
    "        emb = resnet(face_t.unsqueeze(0))[0]\n",
    "    embs.append(emb.cpu().numpy())\n",
    "    print(\"  [Info] 임베딩 추출 완료\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3) 센트로이드 계산\n",
    "if not embs:\n",
    "    raise RuntimeError(f\"[Error] '{sample_dir}'에 유효한 얼굴 샘플이 하나도 없습니다.\")\n",
    "\n",
    "embs = np.stack(embs)\n",
    "centroid = np.mean(embs, axis=0)\n",
    "print(f\"\\n[Success] {embs.shape[0]}개 임베딩으로 센트로이드 생성 완료\")\n",
    "\n",
    "# 이제 `centroid` 변수를 실시간 모자이크/마스킹 파이프라인에 사용하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cca1f8c7-d5e8-4b84-815e-e7a24d7b6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_sample_centroid_simple_fixed2.py 마지막에\n",
    "import numpy as np\n",
    "np.save('centroid.npy', centroid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3b8d3ab-61d0-4eab-b7aa-7f058240202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid = np.load(r'C:\\Users\\ed007\\centroid.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3028a9a6-dab2-47fd-ad6b-d9b004181224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\\\Users\\\\ed007\\\\realtime_mask_with_centroid.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python realtime_mask_with_centroid.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "732d14d6-5bd5-4cbb-a103-6b72668240f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 워킹 디렉터리: C:\\Users\\ed007\n",
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: D4B8-FFA7\n",
      "\n",
      " C:\\Users\\ed007 디렉터리\n",
      "\n",
      "2025-07-05  오후 11:10    <DIR>          .\n",
      "2025-02-28  오전 10:29    <DIR>          ..\n",
      "2025-03-11  오후 01:52    <DIR>          .anaconda\n",
      "2025-07-05  오후 10:29    <DIR>          .cache\n",
      "2025-07-05  오후 11:12    <DIR>          .conda\n",
      "2025-03-11  오후 01:52               146 .condarc\n",
      "2025-03-11  오후 01:52    <DIR>          .continuum\n",
      "2025-07-05  오후 10:20    <DIR>          .ipynb_checkpoints\n",
      "2025-03-11  오후 01:54    <DIR>          .ipython\n",
      "2025-03-11  오후 01:53    <DIR>          .jupyter\n",
      "2025-05-29  오후 05:08    <DIR>          .keras\n",
      "2025-04-01  오후 04:43    <DIR>          .matplotlib\n",
      "2025-03-18  오후 04:53    <DIR>          .vscode\n",
      "2025-06-20  오전 11:23           665,325 23013480 이재욱 데베게 기말 (1) (1).ipynb\n",
      "2025-06-20  오전 11:22           665,325 23013480 이재욱 데베게 기말.ipynb\n",
      "2025-07-05  오후 10:55    <DIR>          anaconda3\n",
      "2025-03-11  오후 01:53    <DIR>          anaconda_projects\n",
      "2025-07-05  오후 11:03             2,176 centroid.npy\n",
      "2025-06-20  오전 10:32                44 cluster_example.csv\n",
      "2025-06-20  오전 10:32            10,369 cluster_example.xlsx\n",
      "2025-02-28  오전 10:09    <DIR>          Contacts\n",
      "2025-04-02  오후 06:35    <DIR>          CONTEST\n",
      "2025-06-14  오후 04:00    <DIR>          data\n",
      "2025-05-20  오전 10:47    <DIR>          database\n",
      "2025-04-14  오후 08:40           689,934 database.ipynb\n",
      "2025-04-05  오후 07:27             2,246 databasehomework.ipynb\n",
      "2025-06-08  오후 08:56            16,701 deeplearning.ipynb\n",
      "2025-07-05  오후 10:57            28,104 deploy.prototxt\n",
      "2025-02-28  오전 10:12    <DIR>          Documents\n",
      "2025-07-05  오후 09:04    <DIR>          Downloads\n",
      "2025-02-28  오전 10:09    <DIR>          Favorites\n",
      "2025-06-20  오전 10:23            16,344 final.ipynb\n",
      "2025-07-05  오후 10:32    <DIR>          group\n",
      "2025-05-28  오후 10:52               105 Index\n",
      "2025-06-20  오전 11:24            32,264 LDA.png\n",
      "2025-06-20  오전 10:50            32,264 LDA_wind.png\n",
      "2025-02-28  오전 10:09    <DIR>          Links\n",
      "2025-05-01  오후 04:04            26,581 mid-term (6).ipynb\n",
      "2025-04-14  오후 07:15             9,944 missing.xlsx\n",
      "2025-02-28  오전 10:09    <DIR>          Music\n",
      "2025-07-05  오후 07:27    <DIR>          OneDrive\n",
      "2025-07-05  오후 11:02    <DIR>          sample\n",
      "2025-04-14  오후 06:48               239 sample1.csv\n",
      "2025-04-14  오후 06:48               196 sample2.txt\n",
      "2025-04-14  오후 06:48               187 sample3.txt\n",
      "2025-04-14  오후 06:48            11,531 sample4.xlsx\n",
      "2025-02-28  오전 10:09    <DIR>          Saved Games\n",
      "2025-05-01  오후 05:08    <DIR>          scikit_learn_data\n",
      "2025-02-28  오전 10:29    <DIR>          Searches\n",
      "2025-03-06  오후 09:44    <DIR>          source\n",
      "2025-05-29  오후 05:29            56,536 Untitled.ipynb\n",
      "2025-06-05  오후 02:48           835,534 Untitled1.ipynb\n",
      "2025-06-19  오후 09:53               617 Untitled2.ipynb\n",
      "2025-07-05  오후 11:10            83,282 Untitled3.ipynb\n",
      "2025-03-01  오후 06:24    <DIR>          Videos\n",
      "2025-04-29  오후 08:05             6,636 weather.csv\n",
      "2025-05-01  오후 04:03             2,056 wine.csv\n",
      "2025-05-28  오후 10:52            10,782 wine.data\n",
      "2025-05-28  오후 10:52             3,036 wine.names\n",
      "2025-06-20  오전 10:48            22,133 wine_class_data.xlsx\n",
      "2025-05-29  오전 10:44            11,727 wine_complete.csv\n",
      "2025-07-05  오후 10:21         6,549,796 yolov8n.pt\n",
      "2025-06-14  오후 04:29           288,709 기계학습 320.ipynb\n",
      "2025-06-19  오후 11:33    <DIR>          기계학습 보고서\n",
      "2025-06-05  오후 02:44        25,069,850 대전.csv\n",
      "2025-06-05  오후 02:44        21,826,682 세종.csv\n",
      "2025-06-04  오후 01:55            10,947 시도별_요양기관_현황_20250601210607.xlsx\n",
      "2025-05-01  오후 04:13            34,894 이재욱 (5) (2).ipynb\n",
      "2025-06-08  오후 08:20             4,988 이재욱_23013480.py\n",
      "2025-06-08  오후 09:40            49,801 재욱_23013480.ipynb\n",
      "2025-06-08  오후 09:39            20,013 재욱_23013480.py\n",
      "2025-06-08  오후 09:06           231,964 재욱_230134801.ipynb\n",
      "2025-06-01  오후 11:38            31,370 주요_인구지표_성비_인구성장률_인구구조_부양비_등__시도_20250522141346.xlsx\n",
      "              41개 파일          57,361,378 바이트\n",
      "              32개 디렉터리  336,278,155,264 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"현재 워킹 디렉터리:\", os.getcwd())\n",
    "!dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c5e3071-ea67-4856-83a4-a289f336b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet ultralytics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
